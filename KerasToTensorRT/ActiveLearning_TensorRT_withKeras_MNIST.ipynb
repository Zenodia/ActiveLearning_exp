{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct keras model and load pretrained weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/data/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/data/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# build function for the Keras' scikit-learn API\n",
    "def create_keras_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                   activation='relu',\n",
    "                   input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.load_weights('nhwc_model.h5')\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                optimizer=keras.optimizers.Adadelta(),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load datasets for testing purpose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wrap keras model into Scikit_learn API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /data/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /data/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 29s 479us/step - loss: 0.0357 - acc: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7abc0574e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier ,Sequential,absolute_import\n",
    "\n",
    "classifier = KerasClassifier(build_fn=create_keras_model,nb_epoch=1)\n",
    "\n",
    "classifier.fit(x_train,y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ensure the scikit-learn Keras API loaded model can indeed make prediction correctly and successfully "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted result is :5 , actual label is :5\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "rn=random.randint(0,len(x_train))\n",
    "sample_x=x_train[rn].reshape(1,28,28,1)\n",
    "out=classifier.predict(sample_x)\n",
    "print(\" predicted result is :{} , actual label is :{}\".format(str(out[0]),str(np.argmax(y_train[rn]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load TensorRT as inference engine and wrap scikit-learn keras API model into it's inference engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import tensorflow as tf\n",
    "import tensorrt as trt\n",
    "\n",
    "import time\n",
    "import uff\n",
    "import utils.ascii as helper\n",
    "import utils.dataset as data\n",
    "from pdb import set_trace\n",
    "from tensorflow.contrib import tensorrt as tftrt\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import utils.ascii as helper\n",
    "import utils.dataset as data\n",
    "img_h = x_test.shape[1]\n",
    "img_w = x_test.shape[2]\n",
    "#helper.print_ascii(x_test[0], img_h, img_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrozenGraph(object):\n",
    "    def __init__(self, model, shape):\n",
    "        shape = (None, shape[0], shape[1], shape[2])\n",
    "        x_name = 'image_tensor_x'\n",
    "        with K.get_session() as sess:\n",
    "            x_tensor = tf.placeholder(tf.float32, shape, x_name)\n",
    "            K.set_learning_phase(0)\n",
    "            y_tensor = model(x_tensor)\n",
    "            y_name = y_tensor.name[:-2]\n",
    "            graph = sess.graph.as_graph_def()\n",
    "            graph0 = tf.graph_util.convert_variables_to_constants(sess, graph, [y_name])\n",
    "            graph1 = tf.graph_util.remove_training_nodes(graph0)\n",
    "\n",
    "        self.x_name = [x_name]\n",
    "        self.y_name = [y_name]\n",
    "        self.frozen = graph1\n",
    "\n",
    "class TfEngine(object):\n",
    "    def __init__(self, graph):\n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            x_op, y_op = tf.import_graph_def(\n",
    "              graph_def=graph.frozen, return_elements=graph.x_name + graph.y_name)\n",
    "            self.x_tensor = x_op.outputs[0]\n",
    "            self.y_tensor = y_op.outputs[0]\n",
    "\n",
    "            config = tf.ConfigProto(gpu_options=\n",
    "            tf.GPUOptions(per_process_gpu_memory_fraction=0.5,\n",
    "            allow_growth=True))\n",
    "\n",
    "        self.sess = tf.Session(graph=g, config=config)\n",
    "\n",
    "    def infer(self, x):\n",
    "        y = self.sess.run(self.y_tensor,\n",
    "          feed_dict={self.x_tensor: x})\n",
    "        return y\n",
    "\n",
    "class TftrtEngine(TfEngine):\n",
    "    def __init__(self, graph, batch_size, precision):\n",
    "        tftrt_graph = tftrt.create_inference_graph(\n",
    "          graph.frozen,\n",
    "          outputs=graph.y_name,\n",
    "          max_batch_size=batch_size,\n",
    "          max_workspace_size_bytes=1 << 30,\n",
    "          precision_mode=precision,\n",
    "          minimum_segment_size=2)\n",
    "\n",
    "        opt_graph = copy.deepcopy(graph)\n",
    "        opt_graph.frozen = tftrt_graph\n",
    "        super(TftrtEngine, self).__init__(opt_graph)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def infer(self, x):\n",
    "        num_tests = x.shape[0]\n",
    "        y = np.empty((num_tests, self.y_tensor.shape[1]), np.float32)\n",
    "        batch_size = self.batch_size\n",
    "\n",
    "        for i in range(0, num_tests, batch_size):\n",
    "            x_part = x[i : i + batch_size]\n",
    "            y_part = self.sess.run(self.y_tensor,\n",
    "            feed_dict={self.x_tensor: x_part})\n",
    "            y[i : i + batch_size] = y_part\n",
    "        return y\n",
    "\n",
    "def verify(result, ans):\n",
    "    num_tests = ans.shape[0]\n",
    "    error = 0\n",
    "    for i in range(0, num_tests):\n",
    "        a = np.argmax(ans[i])\n",
    "        r = np.argmax(result[i])\n",
    "        if (a != r) : error += 1\n",
    "\n",
    "    if (error == 0) : print('PASSED')\n",
    "    else            : print('FAILURE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert y_test to both OHE and Numerical format for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_test_num=np.argmax(y_test,axis=1)\n",
    "y_test_num.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verify how long it takes for the scikit-learn classifier to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras time 0.7310318946838379\n",
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "# use Keras scikit learn --> learner to do infer\n",
    "t0 = time.time()\n",
    "y_learner = classifier.predict(x_test)\n",
    "t1 = time.time()\n",
    "print('Keras time', t1 - t0)\n",
    "verify(y_learner, y_test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the model back to architecture and weight to convert it back to keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.model.model.summary()\n",
    "\n",
    "# saving model\n",
    "json_model = classifier.model.to_json()\n",
    "open('AL2keras.json', 'w').write(json_model)\n",
    "# saving weights\n",
    "classifier.model.save_weights('AL2keras.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the saved architecture and weight back to keras model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /data/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# loading model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model = model_from_json(open('AL2keras.json').read())\n",
    "model.load_weights('AL2keras.h5')\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                optimizer=keras.optimizers.Adadelta(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use TensorRT to accelerate prediction with keras as input model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-42c9fcdc2f52>:11: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /data/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n",
      "WARNING:tensorflow:From <ipython-input-6-42c9fcdc2f52>:12: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.remove_training_nodes\n",
      "(10000, 10)\n",
      "Tensorflow time 1.223820447921753\n",
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "frozen_graph = FrozenGraph(model, (img_h, img_w, 1))\n",
    "\n",
    "tf_engine = TfEngine(frozen_graph)\n",
    "t0 = time.time() \n",
    "y_tf = tf_engine.infer(x_test)\n",
    "print(y_tf.shape)\n",
    "t1 = time.time()\n",
    "print('Tensorflow time', t1 - t0)\n",
    "y_tf_c=np.argmax(y_tf,axis=1)\n",
    "y_tf_c.shape\n",
    "verify(y_tf_c,y_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/modAL-python/modAL.git\n",
      "  Cloning https://github.com/modAL-python/modAL.git to /tmp/pip-req-build-u0tz7vd3\n",
      "  Running command git clone -q https://github.com/modAL-python/modAL.git /tmp/pip-req-build-u0tz7vd3\n",
      "Requirement already satisfied (use --upgrade to upgrade): modAL==0.3.4 from git+https://github.com/modAL-python/modAL.git in /data/anaconda/envs/py35/lib/python3.5/site-packages\n",
      "Requirement already satisfied: numpy>=1.13 in /data/anaconda/envs/py35/lib/python3.5/site-packages (from modAL==0.3.4) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /data/anaconda/envs/py35/lib/python3.5/site-packages (from modAL==0.3.4) (0.20.0)\n",
      "Requirement already satisfied: scipy>=0.18 in /data/anaconda/envs/py35/lib/python3.5/site-packages (from modAL==0.3.4) (1.1.0)\n",
      "Building wheels for collected packages: modAL\n",
      "  Building wheel for modAL (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for modAL: filename=modAL-0.3.4-cp35-none-any.whl size=25056 sha256=65dfc409305ccbd70ba86894a9a8334bd76da88bce36cda148897d512df9f5cd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ozc4dao0/wheels/a6/04/97/a4f7cb2aad1616972b8f2a9bd4fb52d84fbc44f5e9245f05bf\n",
      "Successfully built modAL\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/modAL-python/modAL.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use Active Learning to continous optimize the model's performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 0.0340 - acc: 0.9896\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 1s 677us/step - loss: 0.0323 - acc: 0.9920\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier ,Sequential,absolute_import\n",
    "import numpy as np\n",
    "\n",
    "classifier = KerasClassifier(build_fn=create_keras_model,nb_epoch=1)\n",
    "classifier.fit(x_train,y_train, epochs=1)\n",
    "\n",
    "# assemble initial data\n",
    "n_initial = 1000\n",
    "initial_idx = np.random.choice(range(len(x_train)), size=n_initial, replace=False)\n",
    "X_initial = x_train[initial_idx]\n",
    "y_initial = y_train[initial_idx]\n",
    "\n",
    "# generate the pool\n",
    "# remove the initial data from the training dataset\n",
    "X_pool = np.delete(x_train, initial_idx, axis=0)[:5000]\n",
    "y_pool = np.delete(y_train, initial_idx, axis=0)[:5000]\n",
    "from modAL.models import ActiveLearner\n",
    "\n",
    "# initialize ActiveLearner\n",
    "learner = ActiveLearner(\n",
    "    estimator=classifier,\n",
    "    X_training=X_initial, y_training=y_initial,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query no. 1\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.6812 - acc: 0.7000\n",
      "Query no. 2\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.2807 - acc: 0.9200\n",
      "Query no. 3\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1244 - acc: 0.9600\n",
      "Query no. 4\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0220 - acc: 1.0000\n",
      "Query no. 5\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0183 - acc: 1.0000\n",
      "Query no. 6\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0099 - acc: 1.0000\n",
      "Query no. 7\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0061 - acc: 1.0000\n",
      "Query no. 8\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0069 - acc: 1.0000\n",
      "Query no. 9\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Query no. 10\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.0016 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# the active learning loop\n",
    "n_queries = 10\n",
    "for idx in range(n_queries):\n",
    "    print('Query no. %d' % (idx + 1))\n",
    "    query_idx, query_instance = learner.query(X_pool, n_instances=100, verbose=0)\n",
    "    learner.teach(\n",
    "        X=X_pool[query_idx], y=y_pool[query_idx], only_new=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    # remove queried instance from pool\n",
    "    X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "    y_pool = np.delete(y_pool, query_idx, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check active-learned-model's performance against TensorRT accelerated model inferencing speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "Keras time 0.8184890747070312\n"
     ]
    }
   ],
   "source": [
    "# use Keras scikit learn --> learner to do infer\n",
    "import time\n",
    "t0 = time.time()\n",
    "y_learner = learner.predict(x_test)\n",
    "print(y_learner.shape)\n",
    "t1 = time.time()\n",
    "print('Keras time', t1 - t0)\n",
    "#verify(y_learner, y_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "y_test_num=np.argmax(y_test,axis=1)\n",
    "verify(y_learner, y_test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the learner (active-learning fine-tuned model) and save it back to keras compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# save the learner (active-learning fine-tuned model) and save it back to keras compatible format\n",
    "learner.estimator.model.save('learner2keras.h5')\n",
    "from keras.models import load_model\n",
    "loaded=load_model('learner2keras.h5')\n",
    "loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-42c9fcdc2f52>:11: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /data/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n",
      "WARNING:tensorflow:From <ipython-input-4-42c9fcdc2f52>:12: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.remove_training_nodes\n",
      "(10000, 10)\n",
      "Tensorflow time 1.275697946548462\n",
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "frozen_graph = FrozenGraph(loaded, (28, 28, 1))\n",
    "\n",
    "tf_engine = TfEngine(frozen_graph)\n",
    "t0 = time.time() \n",
    "y_tf = tf_engine.infer(x_test)\n",
    "print(y_tf.shape)\n",
    "t1 = time.time()\n",
    "print('Tensorflow time', t1 - t0)\n",
    "y_tf_c=np.argmax(y_tf,axis=1)\n",
    "y_tf_c.shape\n",
    "verify(y_tf_c,y_test_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
